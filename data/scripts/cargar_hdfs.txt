#!/bin/bash
# cargar_hdfs.sh

# --- CONFIGURACIÃ“N ---
BUCKET="proyectotelematica"
OBJECT_KEY="input/cleaned_gdp_data.csv"
LOCAL_FILE="cleaned_gdp_data.csv"
HDFS_DIR="/user/hadoop/entrada"

# 1. Descargar archivo desde S3

aws s3 cp s3://$BUCKET/$OBJECT_KEY $LOCAL_FILE

# 2. Crear carpeta en HDFS si no existe

hdfs dfs -mkdir -p $HDFS_DIR

# 3. Subir archivo a HDFS

hdfs dfs -put -f $LOCAL_FILE $HDFS_DIR

# 4. Verificar subida

hdfs dfs -ls $HDFS_DIR

# 5. Instalar mrjob si es necesario

python3 -m ensurepip --upgrade
pip3 install --user mrjob
